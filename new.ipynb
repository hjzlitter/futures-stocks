{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt\n",
    "from data import fut_list, fut_read, stock_read\n",
    "from util import adf_test, data_generator, significant, johansen_cointegration_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut = 'CU9999.XSGE'\n",
    "feature = 'ChangeRatio'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA\n",
    "* 数据基础已经全部存在data里了。只需进一步处理得到想要的时间序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hejizhang/Downloads/主连日线-2018年后/data.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fut['ChangeRatio'].iloc[0] = 0\n"
     ]
    }
   ],
   "source": [
    "fut_df = fut_read(fut)\n",
    "stock_df = stock_read(fut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如果想要定制特征，处理fut_df \\ stock_df即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADF验证是否平稳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic                  -33.507513\n",
      "p-value                           0.000000\n",
      "#Lags Used                        0.000000\n",
      "Number of Observations Used    1189.000000\n",
      "Critical Value (1%)              -3.435862\n",
      "Critical Value (5%)              -2.863974\n",
      "Critical Value (10%)             -2.568066\n",
      "dtype: float64\n",
      "Test Statistic                -1.370201e+01\n",
      "p-value                        1.284425e-25\n",
      "#Lags Used                     7.000000e+00\n",
      "Number of Observations Used    1.186000e+03\n",
      "Critical Value (1%)           -3.435876e+00\n",
      "Critical Value (5%)           -2.863980e+00\n",
      "Critical Value (10%)          -2.568069e+00\n",
      "dtype: float64\n",
      "Test Statistic                -1.434570e+01\n",
      "p-value                        1.041917e-26\n",
      "#Lags Used                     7.000000e+00\n",
      "Number of Observations Used    1.176000e+03\n",
      "Critical Value (1%)           -3.435923e+00\n",
      "Critical Value (5%)           -2.864001e+00\n",
      "Critical Value (10%)          -2.568080e+00\n",
      "dtype: float64\n",
      "Test Statistic                  -33.486238\n",
      "p-value                           0.000000\n",
      "#Lags Used                        0.000000\n",
      "Number of Observations Used    1193.000000\n",
      "Critical Value (1%)              -3.435843\n",
      "Critical Value (5%)              -2.863966\n",
      "Critical Value (10%)             -2.568061\n",
      "dtype: float64\n",
      "Test Statistic                  -34.303758\n",
      "p-value                           0.000000\n",
      "#Lags Used                        0.000000\n",
      "Number of Observations Used    1193.000000\n",
      "Critical Value (1%)              -3.435843\n",
      "Critical Value (5%)              -2.863966\n",
      "Critical Value (10%)             -2.568061\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "adf_list = []\n",
    "for idx, df in enumerate(stock_df):\n",
    "   adf_list.append(adf_test(df[feature]))\n",
    "adf_df = pd.concat(adf_list, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test Statistic</th>\n",
       "      <td>-33.507513</td>\n",
       "      <td>-1.370201e+01</td>\n",
       "      <td>-1.434570e+01</td>\n",
       "      <td>-33.486238</td>\n",
       "      <td>-34.303758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-value</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.284425e-25</td>\n",
       "      <td>1.041917e-26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Lags Used</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Observations Used</th>\n",
       "      <td>1189.000000</td>\n",
       "      <td>1.186000e+03</td>\n",
       "      <td>1.176000e+03</td>\n",
       "      <td>1193.000000</td>\n",
       "      <td>1193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Critical Value (1%)</th>\n",
       "      <td>-3.435862</td>\n",
       "      <td>-3.435876e+00</td>\n",
       "      <td>-3.435923e+00</td>\n",
       "      <td>-3.435843</td>\n",
       "      <td>-3.435843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Critical Value (5%)</th>\n",
       "      <td>-2.863974</td>\n",
       "      <td>-2.863980e+00</td>\n",
       "      <td>-2.864001e+00</td>\n",
       "      <td>-2.863966</td>\n",
       "      <td>-2.863966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Critical Value (10%)</th>\n",
       "      <td>-2.568066</td>\n",
       "      <td>-2.568069e+00</td>\n",
       "      <td>-2.568080e+00</td>\n",
       "      <td>-2.568061</td>\n",
       "      <td>-2.568061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0             1             2  \\\n",
       "Test Statistic                -33.507513 -1.370201e+01 -1.434570e+01   \n",
       "p-value                         0.000000  1.284425e-25  1.041917e-26   \n",
       "#Lags Used                      0.000000  7.000000e+00  7.000000e+00   \n",
       "Number of Observations Used  1189.000000  1.186000e+03  1.176000e+03   \n",
       "Critical Value (1%)            -3.435862 -3.435876e+00 -3.435923e+00   \n",
       "Critical Value (5%)            -2.863974 -2.863980e+00 -2.864001e+00   \n",
       "Critical Value (10%)           -2.568066 -2.568069e+00 -2.568080e+00   \n",
       "\n",
       "                                       3            4  \n",
       "Test Statistic                -33.486238   -34.303758  \n",
       "p-value                         0.000000     0.000000  \n",
       "#Lags Used                      0.000000     0.000000  \n",
       "Number of Observations Used  1193.000000  1193.000000  \n",
       "Critical Value (1%)            -3.435843    -3.435843  \n",
       "Critical Value (5%)            -2.863966    -2.863966  \n",
       "Critical Value (10%)           -2.568061    -2.568061  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于changeratio而言，是平稳的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据模型找出各个stock的联动显著时间段\n",
    "* 由于只有VAR，故不再对模型选择进行分支。\n",
    "* 由于p=0.05基本找不到显著的时间段，改成了0.10\n",
    "* y是股票的y。第一个p是const的，第二个是期货前一时刻特征的p，第三个是股票前一时刻的特征的p。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_col = []\n",
    "for idx, df in enumerate(stock_df):\n",
    "    data = data_generator(fut_df, df, feature)\n",
    "    sig_col.append(significant(data))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面sig为list。list 0-4表明对应的stock。\n",
    "\n",
    "比如list[0]中，就存了期股联动显著的时间切片。list中第一个数字是时间切片编号，第二个是三个p。p的解释如上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[243, array([0.01900249, 0.08025969, 0.07651239])],\n",
       "  [244, array([0.00802221, 0.03367894, 0.08705076])],\n",
       "  [245, array([0.00516198, 0.02302983, 0.09857396])],\n",
       "  [246, array([0.0027278 , 0.01661509, 0.09190853])],\n",
       "  [247, array([0.0027793 , 0.01518037, 0.07193898])],\n",
       "  [248, array([0.00186688, 0.02301486, 0.08227843])],\n",
       "  [453, array([0.08585224, 0.08576275, 0.01895921])],\n",
       "  [460, array([0.04912781, 0.05750771, 0.03928519])],\n",
       "  [461, array([0.05073228, 0.065799  , 0.04595558])],\n",
       "  [462, array([0.03719201, 0.05737676, 0.04374542])]],\n",
       " [[144, array([0.08462929, 0.0465453 , 0.03118692])],\n",
       "  [248, array([0.00461322, 0.0197691 , 0.08287854])],\n",
       "  [249, array([0.00187695, 0.01028218, 0.07665436])],\n",
       "  [250, array([0.00112932, 0.00855091, 0.08571575])],\n",
       "  [251, array([0.00065519, 0.00820359, 0.09171993])],\n",
       "  [355, array([0.01853959, 0.07489875, 0.03481428])]],\n",
       " [[355, array([0.03795469, 0.06809477, 0.01351023])],\n",
       "  [781, array([0.06248968, 0.04750179, 0.09777602])],\n",
       "  [782, array([0.05183563, 0.06592699, 0.09051435])]],\n",
       " [[466, array([0.0191039 , 0.08544673, 0.08145428])]],\n",
       " [[136, array([0.08032949, 0.03596238, 0.01880609])],\n",
       "  [137, array([0.09946961, 0.03614548, 0.01457158])],\n",
       "  [779, array([0.02303369, 0.00940544, 0.0587838 ])],\n",
       "  [780, array([0.04418957, 0.01614346, 0.06626824])],\n",
       "  [781, array([0.09769779, 0.04315387, 0.09194752])],\n",
       "  [782, array([0.0721509 , 0.05141905, 0.05771011])]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sig_col 即为显著的index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有更进一步的算最佳lead lag,不过都是1，所以似乎不重要了,写在下面。可以尝试下冲击"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "lag_order = model.select_order(15)\n",
    "print(f\"Selected lag order: {lag_order.selected_orders['aic']}\")\n",
    "model_fitted = model.fit(maxlags=lag_order.selected_orders['aic'])\n",
    "print(model_fitted.summary())\n",
    "\n",
    "irf = model_fitted.irf(10) # 10期冲击响应\n",
    "irf.plot(orth=True) # 正交化冲击响应图\n",
    "plt.show()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 协整检验\n",
    "* 只用检验上面的data数据（就是一列是期货数据，一列是股票数据）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!! 只看一次，所以只用了一个break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Results of Johansen Cointegration Test:')\n",
    "# print(f\"Test statistic: {result.lr1}\")\n",
    "# print(f\"Critical values: {result.cvt}\")\n",
    "# print(f\"Eigenstatistics: {result.lr2}\")\n",
    "# print(f\"Eigenvalues: {result.eig}\")\n",
    "Test_statistic = []\n",
    "Critical_values = []\n",
    "Eigenstatistic = []\n",
    "Eigenvalues = []\n",
    "for idx, df in enumerate(stock_df):\n",
    "    data = data_generator(fut_df, df, feature)\n",
    "    test_result = johansen_cointegration_test(data)\n",
    "    Test_statistic.append(test_result.lr1)\n",
    "    Critical_values.append(test_result.cvt)\n",
    "    Eigenstatistic.append(test_result.lr2)\n",
    "    Eigenvalues.append(test_result.eig)\n",
    "    \n",
    "    \n",
    "# 可以很方便的改成df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATE（暂时失败）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Too few treated units: N_t < K+1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((n, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 创建因果推断模型\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 注意：这里我们直接传递Y（结果变量B）、D（处理变量A）和X（协变量）\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m causal_model \u001b[38;5;241m=\u001b[39m \u001b[43mCausalModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 进行因果推断分析\u001b[39;00m\n\u001b[1;32m     19\u001b[0m causal_model\u001b[38;5;241m.\u001b[39mest_via_ols(adj\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/causalinference/causal.py:17\u001b[0m, in \u001b[0;36mCausalModel.__init__\u001b[0;34m(self, Y, D, X)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, D, X):\n\u001b[0;32m---> 17\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mold_data \u001b[38;5;241m=\u001b[39m \u001b[43mData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/causalinference/core/data.py:65\u001b[0m, in \u001b[0;36mData.__init__\u001b[0;34m(self, outcome, treatment, covariates)\u001b[0m\n\u001b[1;32m     63\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToo few control units: N_c < K+1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_t\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 65\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToo few treated units: N_t < K+1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Too few treated units: N_t < K+1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from causalinference import CausalModel\n",
    "\n",
    "# 生成示例数据\n",
    "np.random.seed(0)\n",
    "n = 1000\n",
    "A = np.random.normal(loc=0, scale=1, size=n)\n",
    "B = 2 * A + np.random.normal(loc=0, scale=1, size=n)\n",
    "\n",
    "# 由于示例中没有协变量X，我们可以创建一个全为1的数组作为占位符\n",
    "# 这样做是为了满足CausalModel的参数要求\n",
    "X = np.ones((n, 1))\n",
    "\n",
    "# 创建因果推断模型\n",
    "# 注意：这里我们直接传递Y（结果变量B）、D（处理变量A）和X（协变量）\n",
    "causal_model = CausalModel(Y=B, D=A, X=X)\n",
    "\n",
    "# 进行因果推断分析\n",
    "causal_model.est_via_ols(adj=1)\n",
    "print(causal_model.estimates)\n",
    "\n",
    "# 获取平均因果效应（ATE）\n",
    "ate = causal_model.estimates['ols']['ate']\n",
    "print(\"Average Treatment Effect (ATE):\", ate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
